{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shernee/CMPE256_SentimentAnalysis/blob/main/CodeBooks/Sentiment_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bShjUJHxds3",
        "outputId": "e8d911fd-09ec-48d3-f8f7-d5d8e780be2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfWtKB-bxuIf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import gzip\n",
        "import json\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import plotly.express as px\n",
        "import numpy as np\n",
        "from scipy import sparse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58iI_XQKzHR8"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.linear_model import Perceptron, LogisticRegression, SGDClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.svm import SVC"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Read review features pickle file and labeled products review data"
      ],
      "metadata": {
        "id": "FJ7iUNW0PSZd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOPI6zCmxzfF"
      },
      "outputs": [],
      "source": [
        "df_sentiment = pd.read_pickle('/content/drive/MyDrive/Sentiment_data/allproducts_labeled.pkl')\n",
        "df_features = pd.read_pickle('/content/drive/MyDrive/Sentiment_data/all_products_review_features_df.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_features.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "z4Mj9UAzDJqa",
        "outputId": "c8192bd4-8e3c-46e4-d28a-06a7641b8f25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  review_length  \\\n",
              "0                                DOESN'T FIT MY LG 4              5   \n",
              "1  Fits very nicely as long as you follow proper ...             12   \n",
              "2  It holds the phone very well enough.\\nBut it's...             28   \n",
              "3  When you have an iPhone you usually go one of ...            241   \n",
              "4  This is my second Armorbox. I wore the first o...             43   \n",
              "\n",
              "   token_count  stopword_count  punctuation_count  lemma_count  \\\n",
              "0            7               3                  1            3   \n",
              "1           13               5                  1            7   \n",
              "2           34              13                  4           17   \n",
              "3          302             143                 39          120   \n",
              "4           48              19                  4           25   \n",
              "\n",
              "                                              lemmas  \\\n",
              "0                                           fit lg 4   \n",
              "1  fit nicely long follow proper instruction install   \n",
              "2  hold phone well enough arm pretty wobbly push ...   \n",
              "3  iphone usually go one two way choose case eith...   \n",
              "4  second armorbox wore first one working industr...   \n",
              "\n",
              "                                     expanded_lemmas  \n",
              "0                                       not fit lg 4  \n",
              "1  fit nicely long follow proper instruction install  \n",
              "2  hold phone well enough arm pretty wobbly push ...  \n",
              "3  iphone usually go one two way choose case eith...  \n",
              "4  second armorbox wore first one working industr...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-af32fe32-a442-44fe-a31a-6dcbe5c5111b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>review_length</th>\n",
              "      <th>token_count</th>\n",
              "      <th>stopword_count</th>\n",
              "      <th>punctuation_count</th>\n",
              "      <th>lemma_count</th>\n",
              "      <th>lemmas</th>\n",
              "      <th>expanded_lemmas</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DOESN'T FIT MY LG 4</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>fit lg 4</td>\n",
              "      <td>not fit lg 4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Fits very nicely as long as you follow proper ...</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>fit nicely long follow proper instruction install</td>\n",
              "      <td>fit nicely long follow proper instruction install</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It holds the phone very well enough.\\nBut it's...</td>\n",
              "      <td>28</td>\n",
              "      <td>34</td>\n",
              "      <td>13</td>\n",
              "      <td>4</td>\n",
              "      <td>17</td>\n",
              "      <td>hold phone well enough arm pretty wobbly push ...</td>\n",
              "      <td>hold phone well enough arm pretty wobbly push ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>When you have an iPhone you usually go one of ...</td>\n",
              "      <td>241</td>\n",
              "      <td>302</td>\n",
              "      <td>143</td>\n",
              "      <td>39</td>\n",
              "      <td>120</td>\n",
              "      <td>iphone usually go one two way choose case eith...</td>\n",
              "      <td>iphone usually go one two way choose case eith...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This is my second Armorbox. I wore the first o...</td>\n",
              "      <td>43</td>\n",
              "      <td>48</td>\n",
              "      <td>19</td>\n",
              "      <td>4</td>\n",
              "      <td>25</td>\n",
              "      <td>second armorbox wore first one working industr...</td>\n",
              "      <td>second armorbox wore first one working industr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af32fe32-a442-44fe-a31a-6dcbe5c5111b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-af32fe32-a442-44fe-a31a-6dcbe5c5111b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-af32fe32-a442-44fe-a31a-6dcbe5c5111b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_sentiment.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PofXGDwSA3mC",
        "outputId": "79258751-f89e-43ef-dbeb-f045d341dc98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  \\\n",
              "0                                DOESN'T FIT MY LG 4   \n",
              "1  Fits very nicely as long as you follow proper ...   \n",
              "2  It holds the phone very well enough.\\nBut it's...   \n",
              "3  When you have an iPhone you usually go one of ...   \n",
              "4  This is my second Armorbox. I wore the first o...   \n",
              "\n",
              "                                              lemmas  \\\n",
              "0                                           fit lg 4   \n",
              "1  fit nicely long follow proper instruction install   \n",
              "2  hold phone well enough arm pretty wobbly push ...   \n",
              "3  iphone usually go one two way choose case eith...   \n",
              "4  second armorbox wore first one working industr...   \n",
              "\n",
              "                                            polarity  sentiment  \\\n",
              "0  {'neg': 0.0, 'neu': 0.286, 'pos': 0.714, 'comp...          1   \n",
              "1  {'neg': 0.0, 'neu': 0.481, 'pos': 0.519, 'comp...          1   \n",
              "2  {'neg': 0.094, 'neu': 0.657, 'pos': 0.249, 'co...          1   \n",
              "3  {'neg': 0.063, 'neu': 0.575, 'pos': 0.362, 'co...          1   \n",
              "4  {'neg': 0.045, 'neu': 0.638, 'pos': 0.317, 'co...          1   \n",
              "\n",
              "                                     expanded_lemmas  \n",
              "0                                       not fit lg 4  \n",
              "1  fit nicely long follow proper instruction install  \n",
              "2  hold phone well enough arm pretty wobbly push ...  \n",
              "3  iphone usually go one two way choose case eith...  \n",
              "4  second armorbox wore first one working industr...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-11fd2352-1735-44e3-b346-fee0553cf23b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>lemmas</th>\n",
              "      <th>polarity</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>expanded_lemmas</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DOESN'T FIT MY LG 4</td>\n",
              "      <td>fit lg 4</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.286, 'pos': 0.714, 'comp...</td>\n",
              "      <td>1</td>\n",
              "      <td>not fit lg 4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Fits very nicely as long as you follow proper ...</td>\n",
              "      <td>fit nicely long follow proper instruction install</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.481, 'pos': 0.519, 'comp...</td>\n",
              "      <td>1</td>\n",
              "      <td>fit nicely long follow proper instruction install</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It holds the phone very well enough.\\nBut it's...</td>\n",
              "      <td>hold phone well enough arm pretty wobbly push ...</td>\n",
              "      <td>{'neg': 0.094, 'neu': 0.657, 'pos': 0.249, 'co...</td>\n",
              "      <td>1</td>\n",
              "      <td>hold phone well enough arm pretty wobbly push ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>When you have an iPhone you usually go one of ...</td>\n",
              "      <td>iphone usually go one two way choose case eith...</td>\n",
              "      <td>{'neg': 0.063, 'neu': 0.575, 'pos': 0.362, 'co...</td>\n",
              "      <td>1</td>\n",
              "      <td>iphone usually go one two way choose case eith...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This is my second Armorbox. I wore the first o...</td>\n",
              "      <td>second armorbox wore first one working industr...</td>\n",
              "      <td>{'neg': 0.045, 'neu': 0.638, 'pos': 0.317, 'co...</td>\n",
              "      <td>1</td>\n",
              "      <td>second armorbox wore first one working industr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11fd2352-1735-44e3-b346-fee0553cf23b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-11fd2352-1735-44e3-b346-fee0553cf23b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-11fd2352-1735-44e3-b346-fee0553cf23b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Convert the lemmas and labels into numpy vectors"
      ],
      "metadata": {
        "id": "_hCpqU30Pbnj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLzb_74Hx3tn"
      },
      "outputs": [],
      "source": [
        "X = np.array(df_sentiment.loc[:, 'expanded_lemmas'])\n",
        "Y = np.array(df_sentiment.loc[:, 'sentiment'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2p2igVGSz72Z"
      },
      "source": [
        "##Train test split and TDIDF vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMcxU6Mzx51W"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,\n",
        "                                   random_state=104, \n",
        "                                   test_size=0.33)\n",
        "\n",
        "tv = TfidfVectorizer(min_df=0.0, max_df=1.0, ngram_range=(1,2),\n",
        "                     sublinear_tf=True)\n",
        "tv_train_features = tv.fit_transform(X_train)\n",
        "tv_test_features = tv.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Sentiment_data/tdidf.pkl', 'wb') as f:\n",
        "  pickle.dump(tv, f)"
      ],
      "metadata": {
        "id": "X3k_Z3pYSsdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aT1Z2uBC0FF9"
      },
      "source": [
        "##Doc2Vec embeddings with all data and then split into train and test .... not using"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2biLpNrl1zCK"
      },
      "outputs": [],
      "source": [
        "# from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGaV9oD4x58d"
      },
      "outputs": [],
      "source": [
        "# # Make tagged documents for doc2vec\n",
        "# tagged_X = [TaggedDocument(words=_d.split(\" \"), tags=[i]) for i, _d in enumerate(X)]\n",
        "\n",
        "# # tagged_X_train = [TaggedDocument(words=_d.split(\" \"), tags=[i]) for i, _d in enumerate(X_train)]\n",
        "# # tagged_X_test = [TaggedDocument(words=_d.split(\" \"), tags=[i]) for i, _d in enumerate(X_test)]\n",
        "\n",
        "\n",
        "# # Make doc2vec model and save\n",
        "# d2v_train_model = Doc2Vec(\n",
        "#     dm=1,\n",
        "#     vector_size=75,\n",
        "#     window=3,\n",
        "#     min_count=3,\n",
        "#     alpha=0.03, \n",
        "#     min_alpha=0.0007, \n",
        "# )\n",
        "# d2v_train_model.build_vocab(tagged_X)\n",
        "# d2v_train_model.train(tagged_X, total_examples=d2v_train_model.corpus_count, epochs=30)\n",
        "# # d2v_train_model.docvecs.vectors_docs\n",
        "\n",
        "# d2v_train_model.save('/content/drive/MyDrive/Sentiment_data/d2v_model.d2v')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sH5Qh4uU1tUj"
      },
      "outputs": [],
      "source": [
        "# d2v_vectors = Doc2Vec.load('/content/drive/MyDrive/Sentiment_data/d2v_model.d2v')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSFncZYb2ZYz"
      },
      "outputs": [],
      "source": [
        "# X_train_docvecs, X_test_docvecs, Y_train, Y_test = train_test_split(d2v_vectors.docvecs.vectors_docs, Y,\n",
        "#                                    random_state=104, \n",
        "#                                    test_size=0.33)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YWEt5zN0MdD"
      },
      "source": [
        "##SMOTE for balancing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ksq-KZ3zx6C1"
      },
      "outputs": [],
      "source": [
        "smote = SMOTE(sampling_strategy='minority')\n",
        "X_train_resampled, Y_train_resampled = smote.fit_resample(X=tv_train_features, y=Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WYXK6c9x6Jd"
      },
      "outputs": [],
      "source": [
        "print(\"Number of Negative reviews in the original dataset: \",np.count_nonzero(Y_train==0) / len(Y_train))\n",
        "print(\"Number of Positive reviews in the original dataset: \",np.count_nonzero(Y_train==1) / len(Y_train))\n",
        "\n",
        "print(\"Number of Negative reviews in the resampled dataset: \",np.count_nonzero(Y_train_resampled==0) / len(Y_train_resampled))\n",
        "print(\"Number of Positive reviews in the resampled dataset: \",np.count_nonzero(Y_train_resampled==1) / len(Y_train_resampled))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dj3J1sBt0RLC"
      },
      "source": [
        "## Tried Perceptron but not using it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PNQPp3AyTA1"
      },
      "outputs": [],
      "source": [
        "# perceptron_model = Perceptron(penalty='elasticnet', alpha=0.001)\n",
        "# perceptron_model.fit(X_train_resampled, Y_train_resampled)\n",
        "\n",
        "# with open('/content/drive/MyDrive/Sentiment_data/perceptron.pkl', 'wb') as f:\n",
        "#   pickle.dump(perceptron_model, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ivb_Z-9byTMV"
      },
      "outputs": [],
      "source": [
        "# with open('/content/drive/MyDrive/Sentiment_data/perceptron.pkl', 'rb') as f:\n",
        "#   perceptron_model_tdidf_balanced = pickle.load(f)\n",
        "\n",
        "# perceptron_predicted = perceptron_model.predict(tv_test_features)\n",
        "# print(classification_report(y_true=Y_test,y_pred=perceptron_predicted))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ii-lPgrj0Tfo"
      },
      "source": [
        "## training the model using Logistic regression algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvx4Pgd9yTVG"
      },
      "outputs": [],
      "source": [
        "# LR on tdidf vectors without smote\n",
        "lr_model_unbalanced = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5)\n",
        "lr_model_unbalanced.fit(tv_train_features, Y_train)\n",
        "\n",
        "with open('/content/drive/MyDrive/Sentiment_data/lr_unbalanced.pkl', 'wb') as f:\n",
        "  pickle.dump(lr_model_unbalanced, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##generating the classification report for LR, our primary metric being Precision and then F1-score"
      ],
      "metadata": {
        "id": "X7dFv81NP-wo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DG7ZQXVdyhw8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bd98adb-d7f3-4bf3-ea46-a58e11c5a1e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.63      0.74     22930\n",
            "           1       0.97      1.00      0.98    306926\n",
            "\n",
            "    accuracy                           0.97    329856\n",
            "   macro avg       0.94      0.81      0.86    329856\n",
            "weighted avg       0.97      0.97      0.97    329856\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# with open('/content/drive/MyDrive/Sentiment_data/lr_unbalanced.pkl', 'rb') as f:\n",
        "#   lr_model_tdidf_unbalanced = pickle.load(f)\n",
        "\n",
        "lr_predicted_tdidf_unbalanced = lr_model_unbalanced.predict(tv_test_features)\n",
        "print(classification_report(y_true=Y_test, y_pred=lr_predicted_tdidf_unbalanced))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjwGlIaeyiQU"
      },
      "outputs": [],
      "source": [
        "# LR on tdidf vectors after smote\n",
        "lr_model_balanced = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5)\n",
        "lr_model_balanced.fit(X_train_resampled, Y_train_resampled)\n",
        "\n",
        "with open('/content/drive/MyDrive/Sentiment_data/lr_balanced.pkl', 'wb') as f:\n",
        "  pickle.dump(lr_model_balanced, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzYy4wQTyiVd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d715499-d8aa-4fc7-a26c-a8d6f1e4dc64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.88      0.69     22930\n",
            "           1       0.99      0.95      0.97    306926\n",
            "\n",
            "    accuracy                           0.95    329856\n",
            "   macro avg       0.78      0.92      0.83    329856\n",
            "weighted avg       0.96      0.95      0.95    329856\n",
            "\n"
          ]
        }
      ],
      "source": [
        "with open('/content/drive/MyDrive/Sentiment_data/lr_balanced.pkl', 'rb') as f:\n",
        "  lr_model_tdidf_balanced = pickle.load(f)\n",
        "\n",
        "lr_predicted_tdidf_balanced = lr_model_balanced.predict(tv_test_features)\n",
        "print(classification_report(y_true=Y_test,y_pred=lr_predicted_tdidf_balanced))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuLlbyYp28sR"
      },
      "outputs": [],
      "source": [
        "# # LR on docvec embeddings without smote\n",
        "# lr_model_docvecs_unbalanced = LogisticRegression(penalty='none', solver='saga')\n",
        "# lr_model_docvecs_unbalanced.fit(X_train_docvecs, Y_train)\n",
        "\n",
        "# with open('/content/drive/MyDrive/Sentiment_data/lr_docvecs_unbalanced.pkl', 'wb') as f:\n",
        "#   pickle.dump(lr_model_docvecs_unbalanced, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GB7ipIgU3VhI",
        "outputId": "3d7f80fb-6e85-4a1c-abbd-207eec4c3d99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.13      0.20     22930\n",
            "           1       0.94      0.99      0.96    306926\n",
            "\n",
            "    accuracy                           0.93    329856\n",
            "   macro avg       0.71      0.56      0.58    329856\n",
            "weighted avg       0.91      0.93      0.91    329856\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# lr_predicted_docvecs_unbalanced = lr_model_docvecs_unbalanced.predict(X_test_docvecs)\n",
        "# print(classification_report(y_true=Y_test, y_pred=lr_predicted_docvecs_unbalanced))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BO-eCAK84t1n"
      },
      "outputs": [],
      "source": [
        "# # LR on docvec embeddings after smote\n",
        "# lr_model_docvecs_balanced = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5)\n",
        "# lr_model_docvecs_balanced.fit(X_train_docvecs_resampled, Y_train_docvecs_resampled)\n",
        "\n",
        "# with open('/content/drive/MyDrive/Sentiment_data/lr_docvecs_balanced.pkl', 'wb') as f:\n",
        "#   pickle.dump(lr_model_docvecs_balanced, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-DA375P5AMQ",
        "outputId": "e3d41ece-9b00-4f00-aab2-7e687f67b87e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.23      0.77      0.36     22930\n",
            "           1       0.98      0.81      0.89    306926\n",
            "\n",
            "    accuracy                           0.81    329856\n",
            "   macro avg       0.61      0.79      0.62    329856\n",
            "weighted avg       0.93      0.81      0.85    329856\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# lr_predicted_docvecs_balanced = lr_model_docvecs_balanced.predict(X_test_docvecs)\n",
        "# print(classification_report(y_true=Y_test, y_pred=lr_predicted_docvecs_balanced))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptfmryW20Wo9"
      },
      "source": [
        "##Trained model using SGD classifier and Multinomial Naive bayes, LR, Adaboost, Random forest, SVC to select best performing model , Chose LR model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h974OQavyibE"
      },
      "outputs": [],
      "source": [
        "sgd_model = SGDClassifier(loss='hinge', alpha=0.001)\n",
        "sgd_model.fit(X_train_resampled, Y_train_resampled)\n",
        "\n",
        "with open('/content/drive/MyDrive/Sentiment_data/sgd.pkl', 'wb') as f:\n",
        "  pickle.dump(sgd_model, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVYVYpuTyzFM"
      },
      "outputs": [],
      "source": [
        "sgd_predicted = sgd_model.predict(tv_test_features)\n",
        "print(classification_report(y_true=Y_test, y_pred=sgd_predicted))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBG9mMEF0ZE0"
      },
      "source": [
        "Multinomial Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckxDhaR3yzKd"
      },
      "outputs": [],
      "source": [
        "mnb_model = MultinomialNB()\n",
        "mnb_model.fit(X_train_resampled, Y_train_resampled)\n",
        "\n",
        "with open('/content/drive/MyDrive/Sentiment_data/mnb.pkl', 'wb') as f:\n",
        "  pickle.dump(mnb_model, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvIVaLTcyzQV"
      },
      "outputs": [],
      "source": [
        "mnb_predicted = mnb_model.predict(tv_test_features)\n",
        "print(classification_report(y_true=Y_test, y_pred=mnb_predicted))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCFcFtlt0cCb"
      },
      "source": [
        "AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lflq_EuAyzWd"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "sgd_ada_model = SGDClassifier(loss='hinge', alpha=0.001)\n",
        "\n",
        "ab_model_tdidf_balanced = AdaBoostClassifier(n_estimators=50, base_estimator=sgd_ada_model, learning_rate=0.5, algorithm='SAMME')\n",
        "ab_model_tdidf_balanced.fit(X_train_resampled, Y_train_resampled)\n",
        "\n",
        "with open('/content/drive/MyDrive/Sentiment_data/ab_tdidf_balanced.pkl', 'wb') as f:\n",
        "  pickle.dump(ab_model_tdidf_balanced, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ab_predicted_tdidf_balanced = ab_model_tdidf_balanced.predict(tv_test_features)\n",
        "print(classification_report(y_true=Y_test, y_pred=ab_predicted_tdidf_balanced))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPy0nYBu_zLL",
        "outputId": "7d99cf32-adbb-4218-901f-0bc56f3b4d21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.83      0.47     22930\n",
            "           1       0.99      0.87      0.93    306926\n",
            "\n",
            "    accuracy                           0.87    329856\n",
            "   macro avg       0.66      0.85      0.70    329856\n",
            "weighted avg       0.94      0.87      0.89    329856\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85U1Mqf20gji"
      },
      "source": [
        "Random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7w5U2lG0fVL"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_model_tdidf_balanced = RandomForestClassifier(n_estimators=50, min_samples_split=30, max_depth=150)\n",
        "rf_model_tdidf_balanced.fit(X_train_resampled, Y_train_resampled)\n",
        "\n",
        "with open('/content/drive/MyDrive/Sentiment_data/rf_tdidf_balanced.pkl', 'wb') as f:\n",
        "  pickle.dump(rf_model_tdidf_balanced, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKS57A-afZvJ",
        "outputId": "971e1cc5-4421-42bb-8b5c-1e4e028139ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.57      0.55     22930\n",
            "           1       0.97      0.96      0.96    306926\n",
            "\n",
            "    accuracy                           0.93    329856\n",
            "   macro avg       0.75      0.77      0.76    329856\n",
            "weighted avg       0.94      0.93      0.94    329856\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rf_predicted_tdidf_balanced = rf_model_tdidf_balanced.predict(tv_test_features)\n",
        "print(classification_report(y_true=Y_test, y_pred=rf_predicted_tdidf_balanced))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YL4FTQaL7da3"
      },
      "source": [
        "SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkVy6pTV0ffT"
      },
      "outputs": [],
      "source": [
        "svc_model_tdidf_balanced = SVC(C=0.01)\n",
        "svc_model_tdidf_balanced.fit(X_train_resampled, Y_train_resampled)\n",
        "\n",
        "with open('/content/drive/MyDrive/Sentiment_data/svc_tdidf_balanced.pkl', 'wb') as f:\n",
        "  pickle.dump(svc_model_tdidf_balanced, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxpcSQ55LF_q"
      },
      "outputs": [],
      "source": [
        "svc_model_docvecs_balanced = SVC(C=0.01)\n",
        "svc_model_docvecs_balanced.fit(X_train_docvecs_resampled, Y_train_docvecs_resampled)\n",
        "\n",
        "with open('/content/drive/MyDrive/Sentiment_data/svc_docvecs_balanced.pkl', 'wb') as f:\n",
        "  pickle.dump(svc_model_docvecs_balanced, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePzy5kEzLbJo"
      },
      "outputs": [],
      "source": [
        "svc_predicted_docvecs_balanced = svc_model_tdidf_balanced.predict(X_test_docvecs)\n",
        "print(classification_report(y_true=Y_test, y_pred=svc_predicted_docvecs_balanced))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##end-to-end Pipeline "
      ],
      "metadata": {
        "id": "XkFLXJ7wQjIe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pipeline for input"
      ],
      "metadata": {
        "id": "BZQXlsi2PMcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.tokenize import wordpunct_tokenize\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.stem import wordnet\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SuxxKAcPsaQ",
        "outputId": "b888307f-1ea6-43b5-b860-8903dcd8e6db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import contractions"
      ],
      "metadata": {
        "id": "s95IhniFVr_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_punctuation_list = list(string.punctuation) + ['...']\n",
        "lem = wordnet.WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_input_review(review_text: str):\n",
        "  expanded_review_text = contractions.fix(\"This isn't the best material\")\n",
        "  all_tokens = wordpunct_tokenize(expanded_review_text)\n",
        "  tokens = []\n",
        "  stopword_count = 0\n",
        "  punctuation_count = 0\n",
        "\n",
        "  for token in all_tokens:\n",
        "    if token not in new_punctuation_list:\n",
        "      cleaned_token = token.lower().replace(\" \",\"\")\n",
        "      if cleaned_token not in new_stopwords_list:\n",
        "        tokens.append(cleaned_token)\n",
        "      else:\n",
        "        stopword_count+=1\n",
        "    else:\n",
        "      punctuation_count+=1\n",
        "\n",
        "  lemmatized_tokens = [lem.lemmatize(token) for token in tokens]\n",
        "  lemma_str = \" \".join(lemmatized_tokens)\n",
        "\n",
        "  return lemma_str\n",
        "\n",
        "def vectorize_input_lemma(lemma_string: str):\n",
        "  with open('/content/drive/MyDrive/Sentiment_data/tdidf.pkl', 'rb') as f:\n",
        "    tv = pickle.load(f)\n",
        "  input_vector = tv.transform(np.array([lemma_string]))\n",
        "\n",
        "  return input_vector\n",
        "\n",
        "def classify_and_predict(input_vector):\n",
        "  with open('/content/drive/MyDrive/Sentiment_data/lr_unbalanced.pkl', 'rb') as f:\n",
        "    lr_model_tdidf_unbalanced = pickle.load(f)\n",
        "\n",
        "  predicted_label = lr_model_tdidf_unbalanced.predict(input_vector)\n",
        "  return predicted_label"
      ],
      "metadata": {
        "id": "a0xf25Y8POw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmas = lemmatize_input_review(\"This isn't the best material\")\n",
        "# lemma_vector = vectorize_input_lemma(lemmas)\n",
        "# prediction = classify_and_predict(lemma_vector)"
      ],
      "metadata": {
        "id": "lwnUs51pRX8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UUBuSNIuRVKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "['Positive' if p==1 else 'Negative' for p in prediction]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W65bdqtVRuR1",
        "outputId": "8395fa44-e7ae-46e2-8be4-1ac6c1d9bed6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Negative']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PiqqOT17RqbR",
        "outputId": "78842393-3f24-4604-e258-0a35c757d3bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'isn best material'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pfkk43g8Qw7g"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}